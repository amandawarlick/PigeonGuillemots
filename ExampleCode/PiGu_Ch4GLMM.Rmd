---
title: "Ch. 4 GLMM"
output: word_document
---

```{r setup, include=FALSE}
library(tidyr)
library(data.table)
library(ggfortify)
library(broom) #tidy() augment()
library(dplyr)
library(ggplot2)
library(cowplot)
library(lme4)
library(lmerTest)
library(scales)
library(reshape2)
library(stats) 
library(zoo)
library(sciplot)
library(jagsUI)
 
setwd("~/Documents/R/SAFS/PigeonGuillemots")
# knitr::opts_chunk$set(echo = TRUE)
```


```{r}

#PiGu data
PG_data_BUGS <- read.csv("PG_data_all.csv", header = T) %>%
  select(year, date, site, week_study, PG_count, intern_data) %>%
  filter(intern_data != 'Y') %>%
  distinct() #%>%
# filter(site %in% c("Cliffside", "Double Bluff North", "Double Bluff South", "Forbes Point", "Fort Casey",
#                    "Harrington North", "Harrington South", "Hastie Lake South", "Keystone", "Lagoon North #1",
#                    "Lagoon North #2", "Lagoon North #3", "Lagoon South", "Ledgewood", "Malmo Bluff", 
#                    "Maylor Point", "Monroe Landing", "Mutiny Sands", "Possession Point", "Pratts Bluff",
#                    "Rolling Hills #1", "Rolling Hills #2", "Shore Meadows", "Swantown"))

PG_weekly_trim_isl <- read.csv("weekly_count_isl_trim.csv", header = T, stringsAsFactors = F)
PG_weekly_trim_col <- read.csv("weekly_count_col_trim.csv", header = T, stringsAsFactors = F)
prey_weeks <- read.csv("prey_weeks.csv", header = T, stringsAsFactors = F)

perc_suc_col <- read.csv("perc_suc_col.csv", header = T, stringsAsFactors = F)
perc_suc_isl <- read.csv("perc_suc_isl.csv", header = T, stringsAsFactors = F)

fledge_col <- prey_weeks %>%
  filter(prey_week_range > 2) %>%
  group_by(year, site) %>%
  summarize(cnt = n_distinct(burrow_name)) %>%
  transform(year = as.numeric(as.character(year)))

fledge_isl <- prey_weeks %>%
  filter(prey_week_range > 2) %>%
  group_by(year) %>%
  summarize(cnt = n_distinct(burrow_name)) %>%
  transform(year = as.numeric(as.character(year)))

#untrimmed
# PG_yearly_island <- PG_data_BUGS %>%
#   filter(intern_data != 'Y') %>%
#   filter(!is.na(PG_count)) %>%
#   group_by(week_study, year) %>%
#   summarize(cnt = sum(PG_count, na.rm = T)) %>% #sum across colonies
#   group_by(year) %>%
#   summarize(PG_count = mean(cnt, na.rm = T)) #mean of weeks

PG_yearly_trim_isl <- PG_weekly_trim_isl %>%
  group_by(year) %>%
  summarize(cnt_mean = round(mean(cnt),0))

PG_yearly_trim_col <- PG_weekly_trim_col %>%
  group_by(year, site) %>%
  summarize(cnt_mean = mean(PG_count))

```


```{r}

#Ch. 4: GLMMS - adding fixed and random effects

#(a) random year effect

#data <- PG_weekly_trim_isl

#attach(data)
mean.year <- mean(1:length(PG_yearly_trim_isl$year))
sd.year <- sd(1:length(PG_yearly_trim_isl$year))
jags.data <- list(C = PG_yearly_trim_isl$cnt_mean, n = length(PG_yearly_trim_isl$cnt_mean),
                 year = (1:length(PG_yearly_trim_isl$year) - mean.year)/sd.year) #center/standardize year covariate

#specify model in BUGS
GLMM_Poisson_PG <- function() {
  
  #priors
  alpha ~ dunif(-20, 20)
  beta1 ~ dunif(-10, 10)
  beta2 ~ dunif(-10, 10)
  tau <- 1/(sd*sd)
  sd ~ dunif(0, 3)
  
  #likelihood
  for(i in 1:n) {
    C[i] ~ dpois(lambda[i]) #distribution of random element
    log(lambda[i]) <- log.lambda[i] #link function
    log.lambda[i] <- alpha + beta1*year[i] + eps[i] #linear predictor & random year effect
    eps[i] ~ dnorm(0, tau) #defines random effects distribution
  } 
}

write.model(GLMM_Poisson_PG, "GLMM_Poisson_PG.txt")
model.filePG = paste(getwd(),"GLMM_Poisson_PG.txt", sep="/")

#initial values 
inits <- function () list(alpha = runif(1, -2, 2),
                          beta1 = runif(1, -3, 3),
                          sd = runif(1, 0, 1)) 

#parameters
params <- c("alpha", "beta1", "lambda", "sd", "eps")

#MCMC
ni <- 1000000
nt <- 2
nb <- 500
nc <- 3

out <- jags(jags.data, inits = inits, 
            parameters.to.save = params,
            model.file = model.filePG, n.chains = nc, 
            n.thin = nt, n.iter = ni,
            n.burnin = nb, parallel = TRUE)

print(out, dig = 3)
#               mean     sd    2.5%     50%   97.5% overlap0     f  Rhat   n.eff
# alpha        6.556  0.192   6.536   6.570   6.601    FALSE 1.000 1.031    7370
# beta1       -0.009  0.091  -0.038  -0.003   0.030     TRUE 0.568 1.033    4880
# lambda[1]  702.121 22.455 654.353 703.469 742.752    FALSE 1.000 1.000  230872
# lambda[2]  724.069 19.974 688.527 722.612 767.740    FALSE 1.000 1.000  421880
# ...
# lambda[9]  709.347 18.525 672.142 709.466 745.934    FALSE 1.000 1.000 1499250
# lambda[10] 717.094 20.507 679.194 716.164 760.342    FALSE 1.000 1.000  564909
# sd           0.041  0.182   0.001   0.023   0.079    FALSE 1.000 1.013    7827
# eps[1]      -0.016  0.111  -0.096  -0.012   0.026     TRUE 0.753 1.064  151496
# eps[2]       0.018  0.123  -0.033   0.006   0.080     TRUE 0.673 1.013   28100
# ...
# eps[9]       0.019  0.284  -0.057  -0.001   0.053     TRUE 0.463 1.045    5771
# eps[10]      0.033  0.314  -0.039   0.004   0.078     TRUE 0.630 1.046    5562
# deviance    93.629  3.333  87.660  93.592 100.914    FALSE 1.000 1.000 1499250

```

```{r}
#(b) variability among groups - year and site random effects

#look at tit.txt to see layouts
# tits <- read.table("tits.txt", header = T)
# C_tits <- as.matrix(tits[5:13])

PG_col_wide <- PG_weekly_trim_col %>%
  group_by(site, year) %>%
  summarize(PG_count = round(mean(PG_count, na.rm = T), 0)) %>%
  dcast(site ~ year, value.var = 'PG_count')

#adjust when add new years of data
C <- as.matrix(PG_col_wide[2:11])

#start with intercept-only model - expect constant over space/time
GLMM_0 <- function() {
  #priors
  alpha ~ dnorm(0, 0.01) #log (mean count)
  #likelihood
  for (i in 1:nyear) {
    for (j in 1:nsite) {
      C[i,j] ~ dpois(lambda[i,j])
      lambda[i,j] <- exp(log.lambda[i,j])
      log.lambda[i,j] <- alpha
    } #j
  } #i
}
write.model(GLMM_0, "GLMM0.txt")
model.fileGLMM0 = paste(getwd(),"GLMM0.txt", sep="/")

#bundle etc.
jags.data <- list(C = t(C), nsite = nrow(C), nyear = ncol(C))

inits <- function() list(alpha = runif(1, -10, 10))
params <- c("alpha")

ni <- 10000
nt <- 2
nb <- 100
nc <- 3

out_0 <- jags(jags.data, inits = inits, 
              parameters.to.save = params,
              model.file = model.fileGLMM0, 
              n.chains = nc, n.thin = nt, n.iter = ni,
              n.burnin = nb, parallel = T) 

print(out_0, 3)
#              mean    sd     2.5%      50%    97.5% overlap0 f Rhat n.eff
# alpha       3.466 0.011    3.445    3.467    3.488    FALSE 1    1 14850
# deviance 4085.274 1.440 4084.246 4084.718 4089.430    FALSE 1    1 14850
# 
# DIC info: (pD = var(deviance)/2) 
# pD = 1 and DIC = 4086.312

```


```{r}
# data same as above
# PG_col_wide <- PG_weekly_trim_col %>%
#   group_by(site, year) %>%
#   summarize(PG_count = round(mean(PG_count, na.rm = T), 0)) %>%
#   dcast(site ~ year, value.var = 'PG_count')
# 
# #adjust when add new years of data
# C <- as.matrix(PG_col_wide[2:11])

#fixed site effects (one-way ANOVA for poisson response)
GLMM_site_f <- function() {
  #priors
  for (j in 1:nsite) {
    alpha[j] ~ dnorm(0, 0.01) #site effect
  }
  #likelihood
  for (i in 1:nyear) {
    for (j in 1:nsite) {
      C[i,j] ~ dpois(lambda[i,j])
      lambda[i,j] <- exp(log.lambda[i,j])
      log.lambda[i,j] <- alpha[j]
    } #j
  } #i
}
write.model(GLMM_site_f, "GLMM_site_f.txt")
model.fileGLMM_site_f = paste(getwd(),"GLMM_site_f.txt", sep="/")

#bundle etc.
jags.data <- list(C = t(C), nsite = nrow(C), nyear = ncol(C))

#something wrong with the initials - won't run with this
#inits <- function() list(alpha = runif(235, -1, 1))
params <- c("alpha")

ni <- 10000
nt <- 2
nb <- 1000
nc <- 3

out_site_f <- jags(jags.data, parameters.to.save = params, model.file = model.fileGLMM_site_f, 
                   n.chains = nc, n.thin = nt, n.iter = ni,
                   n.burnin = nb, parallel = T) 

print(out_site_f, 3)
#               mean    sd     2.5%      50%    97.5% overlap0 f  Rhat n.eff
# alpha[1]     1.661 0.310    1.004    1.676    2.226    FALSE 1 1.000  4899
# alpha[2]     3.399 0.058    3.282    3.400    3.513    FALSE 1 1.000  9271
# alpha[3]     2.505 0.204    2.091    2.513    2.885    FALSE 1 1.000 13500
# ...
# alpha[41]    3.722 0.078    3.567    3.723    3.874    FALSE 1 1.000 13500
# alpha[42]    4.141 0.040    4.062    4.141    4.218    FALSE 1 1.000  9563
# alpha[43]    3.125 0.067    2.993    3.125    3.255    FALSE 1 1.000 13500
# deviance  2055.318 9.409 2039.262 2054.663 2075.976    FALSE 1 1.000 13500

```


```{r}
#fixed site and fixed year (two-way main effects ANOVA for Poisson response)

# data same as above
# PG_col_wide <- PG_weekly_trim_col %>%
#   group_by(site, year) %>%
#   summarize(PG_count = round(mean(PG_count, na.rm = T), 0)) %>%
#   dcast(site ~ year, value.var = 'PG_count')
# 
# #adjust when add new years of data
# C <- as.matrix(PG_col_wide[2:11])

GLMM_siteyr_f <- function() {
  #priors
  for (j in 1:nsite) {
    alpha[j] ~ dnorm(0, 0.01) #site effect
  }
  for (i in 2:nyear) {
    eps[i] ~ dnorm(0, 0.01)
  }
  eps[1] <- 0 #aliased; set value of first level of year effects to zero to avoid overparameterization
  #likelihood
  for (i in 1:nyear) {
    for (j in 1:nsite) {
      C[i,j] ~ dpois(lambda[i,j])
      lambda[i,j] <- exp(log.lambda[i,j])
      log.lambda[i,j] <- alpha[j] + eps[i]
    } #j
  } #i
}
write.model(GLMM_siteyr_f, "GLMM_siteyr_f.txt")
model.fileGLMM_siteyr_f = paste(getwd(),"GLMM_siteyr_f.txt", sep="/")

#bundle etc.
jags.data <- list(C = t(C), nsite = nrow(C), nyear = ncol(C))

inits <- function() list(alpha = runif(235, -1, 1), 
                         eps = c(NA, runif(8, -1, 1)))
params <- c("alpha", "eps")

ni <- 12000
nt <- 2
nb <- 10
nc <- 3

out_siteyr_f <- jags(jags.data, 
                     #inits, 
                     parameters.to.save = params, n.chains = nc, n.thin = nt, n.iter = ni,
                     n.burnin = nb, model.file = model.fileGLMM_siteyr_f, 
                     parallel = TRUE) 

print(out_siteyr_f, 3) 
#               mean     sd     2.5%      50%    97.5% overlap0     f  Rhat n.eff
# alpha[1]     1.720  0.312    1.067    1.740    2.286    FALSE 1.000 1.001  2287
# alpha[2]     3.446  0.067    3.312    3.446    3.574    FALSE 1.000 1.000 17985
# alpha[3]     2.576  0.205    2.159    2.583    2.963    FALSE 1.000 1.000 17985
# ...
# eps[7]      -0.031  0.050   -0.128   -0.031    0.068     TRUE 0.733 1.000 17985
# eps[8]      -0.095  0.052   -0.195   -0.095    0.007     TRUE 0.967 1.000 17985
# eps[9]      -0.094  0.050   -0.193   -0.094    0.004     TRUE 0.970 1.000  7833
# eps[10]     -0.045  0.052   -0.146   -0.045    0.058     TRUE 0.802 1.000 17985
# deviance  2062.023 12.228 2040.558 2061.150 2088.050    FALSE 1.000 1.000  7746

```

```{r}

#random effects - site only

# data same as above
# PG_col_wide <- PG_weekly_trim_col %>%
#   group_by(site, year) %>%
#   summarize(PG_count = round(mean(PG_count, na.rm = T), 0)) %>%
#   dcast(site ~ year, value.var = 'PG_count')
# 
# #adjust when add new years of data
# C <- as.matrix(PG_col_wide[2:11])

GLMM_site_r <- function() {
  #priors
  for (j in 1:nsite) {
    alpha[j] ~ dnorm(mu.alpha, tau.alpha) #random site effects
  }
  mu.alpha ~ dnorm(0, 0.01)
  tau.alpha <- 1/(sd.alpha*sd.alpha)
  sd.alpha ~ dunif(0, 5)
  #likelihood
  for (i in 1:nyear) {
    for (j in 1:nsite) {
      C[i,j] ~ dpois(lambda[i,j])
      lambda[i,j] <- exp(log.lambda[i,j])
      log.lambda[i,j] <- alpha[j]
    } #j
  } #i
}
write.model(GLMM_site_r, "GLMM_site_r.txt")
model.fileGLMM_site_r = paste(getwd(),"GLMM_site_r.txt", sep="/")

#bundle etc.
jags.data <- list(C = t(C), nsite = nrow(C), nyear = ncol(C))

inits <- function() list(mu.alpha = runif(1, 2, 3))
params <- c("alpha", "mu.alpha", "sd.alpha")

ni <- 10000
nt <- 2
nb <- 100
nc <- 3

out_site_r <- jags(jags.data, inits, params,
                   model.file = model.fileGLMM_site_r, n.chains = nc, 
                   n.thin = nt, n.iter = ni, parallel = TRUE) 

print(out_site_r, 3) 
#               mean    sd     2.5%      50%    97.5% overlap0 f  Rhat n.eff
# alpha[1]     1.956 0.244    1.453    1.964    2.413    FALSE 1 1.000  6872
# alpha[2]     3.399 0.057    3.285    3.399    3.511    FALSE 1 1.000 10587
# alpha[3]     2.580 0.185    2.198    2.585    2.927    FALSE 1 1.000 15000
# ...
# mu.alpha     3.262 0.097    3.068    3.263    3.450    FALSE 1 1.000 15000
# sd.alpha     0.619 0.075    0.492    0.612    0.784    FALSE 1 1.000 14329
# deviance  2056.180 9.458 2039.676 2055.397 2076.770    FALSE 1 1.000 15000

```


```{r}

#random effects - site and year

# data same as above
# PG_col_wide <- PG_weekly_trim_col %>%
#   group_by(site, year) %>%
#   summarize(PG_count = round(mean(PG_count, na.rm = T), 0)) %>%
#   dcast(site ~ year, value.var = 'PG_count')
# 
# #adjust when add new years of data
# C <- as.matrix(PG_col_wide[2:11])

GLMM_siteyr_r <- function() {
  #priors
  mu ~ dnorm(0, 0.01) #grand mean
  for (j in 1:nsite) {
    alpha[j] ~ dnorm(0, tau.alpha) #random site effects
  }
  tau.alpha <- 1/(sd.alpha*sd.alpha)
  sd.alpha ~ dunif(0, 5)
  
  for (i in 1:nyear) {
    eps[i] ~ dnorm(0, tau.eps) #random year effects
  }
  tau.eps <- 1/(sd.eps*sd.eps)
  sd.eps ~ dunif(0,3)
  
  #likelihood
  for (i in 1:nyear) {
    for (j in 1:nsite) {
      C[i,j] ~ dpois(lambda[i,j])
      lambda[i,j] <- exp(log.lambda[i,j])
      log.lambda[i,j] <- mu + alpha[j] + eps[i]
    } #j
  } #i
}
write.model(GLMM_siteyr_r, "GLMM_siteyr_r.txt")
model.fileGLMM_siteyr_r = paste(getwd(),"GLMM_siteyr_r.txt", sep="/")

#bundle etc.
jags.data <- list(C = t(C), nsite = nrow(C), nyear = ncol(C))

inits <- function() list(mu = runif(1, 0, 4), 
                         alpha = runif(235, -1, 1),
                         eps = runif(9, -1, 1))
params <- c("mu", "alpha", "eps", "sd.alpha", "sd.eps")

ni <- 10000
nt <- 2
nb <- 100
nc <- 3

out_siteyr_r <- jags(jags.data, 
                     #inits = inits, 
                     parameters.to.save = params,
                     model.file = model.fileGLMM_siteyr_r, n.chains = nc, 
                     n.thin = nt, n.iter = ni,
                     n.burnin = nb, parallel = TRUE) 

print(out_siteyr_r, 3)

#               mean     sd     2.5%      50%    97.5% overlap0     f  Rhat n.eff
# mu           3.205  0.110    2.986    3.205    3.421    FALSE 1.000 1.000  6355
# alpha[1]    -1.259  0.268   -1.805   -1.250   -0.759    FALSE 1.000 1.001  3959
# alpha[2]     0.190  0.123   -0.046    0.190    0.434     TRUE 0.942 1.000  3708
# ...
# eps[9]      -0.031  0.031   -0.098   -0.028    0.024     TRUE 0.848 1.000 14843
# eps[10]     -0.002  0.030   -0.064   -0.001    0.059     TRUE 0.523 1.000  8800
# sd.alpha     0.639  0.087    0.494    0.629    0.837    FALSE 1.000 1.000  7975
# sd.eps       0.046  0.021    0.012    0.043    0.095    FALSE 1.000 1.001 14850
# deviance  2063.115 11.024 2043.745 2062.433 2086.766    FALSE 1.000 1.001  3542

plot(out_siteyr_r)
```

```{r}

# random site/year effects and overall linear time trend

# data same as above
# PG_col_wide <- PG_weekly_trim_col %>%
#   group_by(site, year) %>%
#   summarize(PG_count = round(mean(PG_count, na.rm = T), 0)) %>%
#   dcast(site ~ year, value.var = 'PG_count')
# 
# #adjust when add new years of data
# C <- as.matrix(PG_col_wide[2:11])

L <- PG_weekly_trim_col %>%
  group_by(site, year) %>%
  summarize(PG_count = round(mean(PG_count, na.rm = T), 0)) %>%
  nrow()

GLMM_siteyr_r_trend <- function() {
  #priors
  mu ~ dnorm(0, 0.01) #overall intercept
  beta1 ~ dnorm(0, 0.01) #overall trend
  
  for (j in 1:nsite) {
    alpha[j] ~ dnorm(0, tau.alpha) #random site effects
  }
  tau.alpha <- 1/(sd.alpha*sd.alpha)
  sd.alpha ~ dunif(0, 3)
  
  for (i in 1:nyear) {
    eps[i] ~ dnorm(0, tau.eps) #random year effects
  }
  tau.eps <- 1/(sd.eps*sd.eps)
  sd.eps ~ dunif(0, 1)
  
  #likelihood
  for (i in 1:nyear) {
    for (j in 1:nsite) {
      C[i,j] ~ dpois(lambda[i,j])
      lambda[i,j] <- exp(log.lambda[i,j])
      log.lambda[i,j] <- mu + beta1*year[i] + alpha[j] + eps[i]
    } #j
  } #i
        #for (i in 1:L){
   #resi[i,j] <- C[i,j] - lambda[i,j] # Derived quantities - residuals; could have defined under the likelihood for loop
      #}
}
write.model(GLMM_siteyr_r_trend, "GLMM_siteyr_r_trend.txt")
model.fileGLMM_siteyr_r_trend = paste(getwd(),"GLMM_siteyr_r_trend.txt", sep="/")

#bundle etc.
mean.year <- mean(1:length(PG_yearly_trim_isl$year))
sd.year <- sd(1:length(PG_yearly_trim_isl$year))

jags.data <- list(C = t(C), nsite = nrow(C), nyear = ncol(C), L = L,
                 year = (1:length(PG_yearly_trim_isl$year) - mean.year)/sd.year)

inits <- function() list(mu = runif(1, 0, 4), 
                         alpha = runif(235, -1, 1),
                         beta1 = runif(1, -1, 1),
                         eps = runif(9, -1, 1))
params <- c("mu", "beta1", "alpha", "eps", "sd.alpha", "sd.eps" 
            #, "resi"
            )

ni <- 100000
nt <- 2
nb <- 6000
nc <- 3

out_full <- jags(jags.data, 
                           #inits = inits, 
                     parameters.to.save = params,
                     model.file = model.fileGLMM_siteyr_r_trend, n.chains = nc, 
                     n.thin = nt, n.iter = ni,
                     parallel = TRUE) 

print(out_full, 3)

# par(mfrow = c(1, 2), mar = c(2, 3, 3, 2), cex.lab = 1.5, cex.axis = 1.5)
# plot(out_full)

par(mfrow = c(1, 2), mar = c(5,4,2,3), cex = 0.7)
whiskerplot(out_full, param = c("mu", "beta1", "alpha", "eps", "sd.alpha", "sd.eps")) #, 'resi[c(1,3, 5:7)]'))    
library(denstrip)      # Similar, but more beautiful, with package denstrip
plot(out_full$sims.list$mu, xlim=c(-4, 4), ylim=c(1, 5), xlab="", ylab="", type="n", axes = F, main = "Density strip plots")
axis(1)
axis(2, at = 1:6, labels = c("mu", "beta1", "alpha", "eps", "sd.alpha", "sd.eps"), las = 1)
abline(v = c(-4,-2,2,4), col = "grey")  ;  abline(v = 0)
for(k in 1:6){
   denstrip(unlist(out_full$sims.list[k]), at = k, ticks = out_full$summary[k, c(3,5,7)])
}

#plotting the actual posterior samples for each covariate, in histograms with confidence interval
par(mfrow = c(2, 2), mar = c(5,4,2,3), cex.main = .7)
hist(out_full$sims.list$mu, main = "", breaks = 100, col = "grey", freq = F, cex = 0.7)
abline(v = quantile(out_full$sims.list$beta1, prob = c(0.025, 0.975)), col = "red", lwd = 2)

hist(out_full$sims.list$alpha, main = "", breaks = 100, col = "grey", freq = F)
abline(v = quantile(out_full$sims.list$alpha, prob = c(0.025, 0.975)), col = "red", lwd = 2)

hist(out_full$sims.list$eps, main = "", breaks = 100, col = "grey", freq = F)
abline(v = quantile(out_full$sims.list$eps, prob = c(0.025, 0.975)), col = "red", lwd = 2)


#model in R
data_fm <- PG_weekly_trim_col %>%
  group_by(site, year) %>%
  summarize(PG_count = round(mean(PG_count, na.rm = T), 0))

summary(fm_trend <- glmer(PG_count ~ year + site + (1|site), family = poisson, data = data_fm))

plot(glmer(PG_count ~ year + site + (1| site), family = poisson, data = data_fm))

#same plots using our JAGs output
#TAKES FOREVER, WATCH OUT
# lambda <- out_full$mean$mu + out_full$mean$beta1 * year + out_full$mean$alpha + out_full$mean$eps       # Compute the posterior mean of lambda

par(mfrow = c(2, 2), mar = c(5,4,2,2), cex.main = .7)
# plot(1:L, out1$summary[6:272, 1], xlab = "Order of values", ylab = "Residual", frame.plot = F, ylim = c(-10, 15))
# abline(h = 0, col = "red", lwd = 2)
# segments(1:267, out1$summary[6:272, 3], 1:267, out1$summary[6:272, 7], col = "grey")
# text(10, 14, "A", cex = 1.5)
# hist(out1$summary[6:272, 1], xlab = "Residual", main = "", breaks = 50, col = "grey", xlim = c(-10, 15))
# abline(v = 0, col = "red", lwd = 2)
# text(-9, 48, "B", cex = 1.5)
# qq <- qnorm(seq(0,0.9999,,data$M), mean = 0, sd = out1$summary[5, 1])
# plot(sort(qq), sort(out1$summary[6:272, 1]), xlab = "Theoretical quantile", ylab = "Residual", frame.plot = F, ylim = c(-10, 15)) # could also use qqnorm()
# abline(0, 1, col = "red", lwd = 2)
# text(-4.5, 14, "C", cex = 1.5)
# plot(mu, out1$summary[6:272, 1], xlab = "Predicted values", ylab = "Residual", frame.plot = F, ylim = c(-10, 15))
# abline(h = 0, col = "red", lwd = 2)
# segments(mu, out1$summary[6:272, 3], mu, out1$summary[6:272, 7], col = "grey")
# text(-1, 14, "D", cex = 1.5)

confint(glmer(PG_count ~ year + site + (1| site), family = poisson, data = data_fm))

```

